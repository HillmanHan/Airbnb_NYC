---
title: "Airbnb"
author: "Team39"
date: '2022-09-27'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load data and packages 
```{r}
library(ggplot2)
library(dplyr)
library(corrplot)
library(Rmisc)
library(ragtop)
library(readxl)

library(fastDummies)

library(tree)

Airdf <- read_excel(file.choose())
#Use Airbnb_Open_Data.csv
summary(Airdf)

numV <- which(sapply(Airdf, is.numeric))
numVnames <- names(numV)
catV <- which(sapply(Airdf, is.character))
catVnames <- names(catV)
cat("There are ", length(numV), "numeric variables and ", length(catV), "categorical variables in this dataset")
```

Identify NAs
```{r}
colSums(is.na(Airdf)) #how many NAs in a column
sum(colSums(is.na(Airdf))) #193504 total inputs with NAs
#Yet there are some blank("") inputs that are not captured by the is.na function

NAcolumns <- names(which(colSums(is.na(Airdf)) > 0 )) #which columns have NAs
print(NAcolumns)
cat('There are', length(names(which(colSums(is.na(Airdf)) > 0 ))), 'columns with NAs. ')

getRid <- c("id", "NAME", "host.id", "host.name", "country","country.code", "house_rules", "license")


Airdf1 <- Airdf %>%
      select(-getRid)
```
We decide to get rid of these 8 columns in the original data set. The "id", "name", "host.id", "host.name", "license" columns are too trivial and have very little or no relation with the variable "review.rate.number" we are interested in from empirical perspective. "country" is just the "United States. The other column "house_rules" may be one of the factors that can impact review rate, but due to the difficulty in processing natural language and the the time we have, we decide not to include this column in our further analysis.


Yilun's Part
```{r}

Airdf1 <- filter(Airdf1, !is.na(Airdf1$host_identity_verified))

Airdf1$`neighbourhood.group`[Airdf1$`neighbourhood.group`== "brookln"] <- "Brooklyn"
Airdf1$`neighbourhood.group`[Airdf1$`neighbourhood.group`== "manhatan"] <- "Manhattan"
Airdf1 <- filter(Airdf1, !is.na(Airdf1$`neighbourhood.group`))

Airdf1 <- filter(Airdf1, !is.na(Airdf1$neighbourhood))

Airdf1 <- filter(Airdf1, !is.na(Airdf1$lat))
Airdf1 <- filter(Airdf1, !is.na(Airdf1$long))
```

Ashley's Part
```{r}
# Removing N/As
Airdf1 <- filter(Airdf1, !is.na(Airdf1$instant_bookable))
Airdf1 <- filter(Airdf1, !is.na(Airdf1$Construction.year))
```

Pallavi's Part
```{r}
Airdf1<-Airdf1[!(is.na(Airdf1$price) | Airdf1$price==""), ]
Airdf1<-Airdf1[!(is.na(Airdf1$service.fee) | Airdf1$service.fee==""), ]
Airdf1<-Airdf1[!(is.na(Airdf1$minimum.nights) | Airdf1$minimum.nights=="") | Airdf1$minimum.nights<0, ]
Airdf1<-Airdf1[(Airdf1$minimum.nights<365),]
Airdf1<-Airdf1[!(is.na(Airdf1$number.of.reviews) | Airdf1$number.of.reviews==""), ]
```

Paul's Part
```{r}
#Last.Review
date.reframed <- strptime(Airdf1$last.review, "%m/%d/%Y")
Airdf1 <- data.frame(Airdf1, date.reframed)

Airdf1 <- Airdf1[!(is.na(Airdf1$last.review)),]
Airdf1 <- Airdf1 %>%
      filter(last.review < strptime('10/2/2022', "%m/%d/%Y"))


#Reviews.Per.Month
Airdf1<-Airdf1[!(is.na(Airdf1$reviews.per.month) | Airdf1$reviews.per.month==""), ]

#Review.Rate.Number Filter (Null, Missing Values)
Airdf1<-Airdf1[!(is.na(Airdf1$review.rate.number) | Airdf1$review.rate.number==""), ]

#Calculated.Host.Listings Filter (Null and Missing and Outliers above 5)
#UpperOutlier=Q3+1.5*IQR
Airdf1<-Airdf1[!(is.na(Airdf1$calculated.host.listings.count) | Airdf1$calculated.host.listings.count==""), ]
Airdf1<-Airdf1[(Airdf1$calculated.host.listings.count<5),]

#Availability.365 Filter (Null, Missing, Values below 0 and above 365)
Airdf1<-Airdf1[!(is.na(Airdf1$availability.365) | Airdf1$availability.365==""), ]
Airdf1<-Airdf1[(Airdf1$availability.365>0),]
Airdf1<-Airdf1[(Airdf1$availability.365<365),]

#Since we have filtered out the date beyond 10/2/2022, we can get rid of date.reframed and last.review for modeling purpose.
Airdf1 <- Airdf1%>%select(-c("date.reframed", "last.review"))

```

Data Preparation
```{r}
#number of numeric values
numV <- which(sapply(Airdf1, is.numeric))
length(numV)#11 numeric variables in the data set
#number of character values
charV <- which(sapply(Airdf1, is.character))
length(charV)#5 character variables in the data set
charVnames <- names(charV)
charV
summary(Airdf1)

#The only one left is in Logical Class for instant_bookable we will turn the instant_bookable into numeric, with 0 means False and 1 means True
Airdf1$instant_bookable <- as.character(Airdf1$instant_bookable)
charV <- which(sapply(Airdf1, is.character))
charVnames <- names(charV)
length(charVnames) #now is 6

#Construction Year can also be changed into factors so here we convert it into character first and then we will convert all characters into factors
Airdf1$Construction.year <- as.character(Airdf1$Construction.year)
charV <- which(sapply(Airdf1, is.character))
charVnames <- names(charV)
length(charVnames) #now is 7
numV <- which(sapply(Airdf1, is.numeric))
length(numV) #now is 10

#change categorical variables into factors
for (i in 1:length(charVnames)) {
      Airdf1[,charV[i]] = as.factor(Airdf1[,charV[i]])
}

#sanity check
for (i in 1:length(charVnames)) {
      print(levels(Airdf1[,charV[i]]))
}
#all categorical variables are transformed into factors

#creating dummy variables
Airdf_dum <- dummy_cols(Airdf1, remove_first_dummy = TRUE)
Airdf_dum <- Airdf_dum %>%
      select(-charVnames)
#We can use Airdf_dum for further modeling.
```

```{r}
install.packages("glmnet")
library(glmnet)
install.packages("caTools")
library(caTools)

# Lasso attempt
# Split data into train and test 
Airdf_dum1 <- Airdf_dum
split <- sample.split(Airdf_dum1, SplitRatio = 0.8)
train_data <- subset(Airdf_dum1, split == "TRUE")
test_data <- subset(Airdf_dum1, split == "FALSE")


# Define predictor and response variables
y <- train_data$review.rate.number
Mx <- as.matrix(train_data[,-8])

# fit lasso regression model using k-fold cross-validation
cv_model <- cv.glmnet(Mx, y, alpha = 1)
best_lambda <- cv_model$lambda.min

# display optimal lambda value
best_lambda

# view plot of test MSE's vs. lambda values
plot(cv_model)

# make a prediction for the review rate number for the test data
# need to change input: 
Mx_test <- as.matrix(test_data[,-8])
lasso_predict <- predict(cv_model, s = best_lambda, newx = Mx_test)

# find MSE
mse <- mean((test_data$review.rate.number - lasso_predict)^2)
mse


```


```{r}
# 
nfold <- 2 
n <- nrow(Airdf_dum)
foldid <- rep(1:nfold,each=ceiling(n/nfold))[sample(1:n)]
OOS <- data.frame(logistic.interaction=NA, logistic=NA, tree=NA, null=NA) 

### Set the second part for testing (first for training)
k <- 2
### Set the other part for training (if not k)
train <- which(foldid!=k) # train on all but fold `k'
test  <- which(foldid==k) # test on fold k

### Do not worry about the warning messages. 
### These are minor numerical issues in this case.
model.logistic.interaction <-glm(review.rate.number~.^2, data=Airdf_dum, subset=train, family="binomial")
model.logistic <-glm(review.rate.number~., data=Airdf_dum, subset=train,family="binomial")



```



```{r}
# Post Lasso
PL.OOS <- data.frame(PL.min=rep(NA,nfold), PL.1se=rep(NA,nfold), PL.theory=rep(NA,nfold)) 
L.OOS <- data.frame(L.min=rep(NA,nfold), L.1se=rep(NA,nfold), L.theory=rep(NA,nfold)) 
features.min <- support(lasso$beta[,which.min(lassoCV$cvm)])
length(features.min)
features.1se <- support(lasso$beta[,which.min( (lassoCV$lambda-lassoCV$lambda.1se)^2)])
length(features.1se) 
features.theory <- support(lassoTheory$beta)
length(features.theory)

data.min <- data.frame(Mx[,features.min],My)
data.1se <- data.frame(Mx[,features.1se],My)
data.theory <- data.frame(Mx[,features.theory],My)

for(k in 1:nfold){ 
  train <- which(foldid!=k)
}
```


```{r}
# PCA
library(tidyverse)

#calculate principal components
results <- prcomp(Airdf_dum, scale = TRUE)

#reverse the signs
results$rotation <- -1*results$rotation

#display principal components
results$rotation

#reverse the signs of the scores
results$x <- -1*results$x

#display the first six scores
head(results$x)

#create biplot to visualize results
biplot(results, scale = 0)

#calculate total variance explained by each principal component
var_explained = results$sdev^2 / sum(results$sdev^2)

#create scree plot
qplot(c(1:4), var_explained) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Scree Plot") +
  ylim(0, 1)
```

```{r}

# Heatmap of price & rating of whole dataset 
library(devtools)
library(usdata)
library(usmap)
library(maps)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(urbnmapr)
install.packages("mapview")
library(mapview)
library(ggmap)
library(RColorBrewer)
devtools::install_github('UrbanInstitute/urbnmapr')

NY <- filter(counties, counties$state_abbv=="NY")
NY_new <- filter(NY, NY$county_name == "Bronx County" | NY$county_name == "Kings County" | NY$county_name =="New York County" | NY$county_name == "Queens County"| NY$county_name =="Richmond County")
base_map <- ggplot(data = NY_new, mapping = aes(x = long, y = lat, group = group)) +
  geom_polygon(color = "black", fill = "white") +
  coord_quickmap() +
  theme_void() 
base_map

```
```{r}
map_with_data <- base_map +
  geom_point(data = sampledata, aes(x = long, y = lat, group=price))
map_with_data

min_long <- min(sampledata$long)
max_long <- max(sampledata$long)
min_lat <- min(sampledata$lat)
max_lat <- max(sampledata$lat)

map_with_data_price <- base_map +
  geom_point(data = sampledata, aes(x = long, y = lat, color=price ,group=price),alpha= 0.5, size = 0.5) +
  coord_quickmap(xlim = c(min_long, max_long),  ylim = c(min_lat, max_lat))
map_with_data_price
```


```{r}
map_with_data_review <- base_map +
  geom_point(data = sampledata, aes(x = long, y = lat, color=review.rate.number, group=review.rate.number), alpha= 0.5, size = 0.5) +
  coord_quickmap(xlim = c(min_long, max_long),  ylim = c(min_lat, max_lat))
map_with_data_review

```


```{r}
```